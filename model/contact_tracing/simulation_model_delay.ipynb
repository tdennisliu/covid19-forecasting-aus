{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecast Cases\n",
    "\n",
    "Using a generative model, simulate the number of infectious individuals to forecast at National and State level.\n",
    "\n",
    "We have three types of infectious individuals: Imported $\\left(I_{I}\\right),$ Asymptomatic $\\left(I_{A}\\right),$ and Symptomatic $\\left(I_{S}\\right)$\n",
    "- Each case is assumed to generate a number of cases from a Negative Binomial distribution, with parameters $k$ and, respectively, $\\alpha_{I} R_{\\mathrm{eff}} /\\left(\\alpha_{I} R_{\\mathrm{eff}}+k\\right), \\alpha_{A} R_{\\mathrm{eff}} /\\left(\\alpha_{A} R_{\\mathrm{eff}}+k\\right)$ and $\\alpha_S R_{\\mathrm{eff}} /\\left(\\alpha_S R_{\\mathrm{eff}}+k\\right)$\n",
    "- The parameter $k$ is the shape parameter of an Erlang infectious period; we will likely fix this at $k=3$ (but can try a few values)\n",
    "$-$ The parameters $\\alpha_{I}$ and $\\alpha_{A}$ correspond to the reduced transmissibility of, respectively, imported and asymptomatic cases. Perhaps we want to infer these, but prior (and initial distribution for generation might be $\\operatorname{Beta}(a, b)$ with mean 0.1 and low variance.\n",
    "$-$ The parameter $R_{\\mathrm{eff}}$ can be sampled from David's estimates, or Dennis's model.\n",
    "- New infectious indviduals generated as above are assigned to be Symptomatic with probability $p_{S}$ and are otherwise Asymptomatic.\n",
    "$-$ We might try to infer $p_{S},$ but to start with we might have $p_{S} \\sim \\operatorname{Beta}(c, d)$ such that the mean is 0.5 and variance such that it is reasonably confidently between 0.25 and 0.75\n",
    "- Infectious individuals are detected, and hence become a case, with respective probabilities $q_{I}, q_{A}$ and $q_{S}$ respectively.\n",
    "$-$ We might try to infer these, but to start with I think $q_{A} \\sim \\operatorname{Beta}(e, f)$ such that the mean is 0.001 and low variance, $q_{I}, q_{S} \\sim \\operatorname{Beta}(g, h)$ such that the mean is 0.9 and low variance.\n",
    "- For each infectious individual, we generate the time that they became infected by adding to the time of infection of their parent a random time generated from a Gamma(mean $=i,$ variance $=j$ ) distribution.\n",
    "$-$ We probably want to infer $i$ and $j,$ but to start I think $i=5$ and a reasonably large variance.\n",
    "For those that are detected, we also need to add on to their time of infection the delay until they are detected (which rounded, gives the day they appear in the case data), generated from a Gamma(mean= $k$, variance $=l$ ) distribution.\n",
    "$-$ We probably want to infer $k$ and $l,$ but to start I think $k=6$ and a large (but not as large as infection distribution above)\n",
    "- We additionally have a $\\operatorname{Poi}\\left(\\iota_{t}\\right)$ number of new imported infectious individuals on day $t,$ where $\\iota_{t}$ decreases in time, especially from quarantine restrictions, and to be inferred from data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import nbinom, erlang, beta, binom, gamma, poisson, beta\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "class Person:\n",
    "    \"\"\"\n",
    "    Individuals in the forecast\n",
    "    \"\"\"\n",
    "    # Laura\n",
    "    # default action_time to 0. This allows for code that doesnâ€™t involve contact tracing (undetected cases) \n",
    "    # to continue without modification.\n",
    "    def __init__(self,parent, infection_time,detection_time, detected,category:str, action_time = 0):\n",
    "        \"\"\"\n",
    "        Category is one of 'I','A','S' for Imported, Asymptomatic and Symptomatic\n",
    "        \"\"\"\n",
    "        self.parent = parent\n",
    "        self.infection_time = infection_time\n",
    "        self.detection_time = detection_time\n",
    "        self.detected = detected\n",
    "        self.category = category\n",
    "        # Laura\n",
    "        # Add action time to Person object\n",
    "        self.action_time = action_time\n",
    "    \n",
    "class Forecast:\n",
    "    \"\"\"\n",
    "    Forecast object that contains methods to simulate a forcast forward, given Reff and current state.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,current, state,start_date, people, \n",
    "        Reff=2.2,k=0.1,alpha_i=1,gam_list=[0.8],qi_list=[1], qa_list=[1/8], qs_list=[0.8],\n",
    "        qua_ai= 1, qua_qi_factor=1, qua_qs_factor=1,forecast_R=None,R_I=None,\n",
    "        forecast_date='2020-07-01', cross_border_state=None,cases_file_date=('25Jun','0835'),\n",
    "        ps_list=[0.7], test_campaign_date=None, test_campaign_factor=1,\n",
    "        Reff_file_date=None,\n",
    "        ):\n",
    "        import numpy as np\n",
    "        self.initial_state = current.copy() #Observed cases on start day\n",
    "        #self.current=current\n",
    "        self.state = state\n",
    "        #start date sets day 0 in script to start_date\n",
    "        self.start_date = pd.to_datetime(start_date,format='%Y-%m-%d')\n",
    "        self.quarantine_change_date = pd.to_datetime(\n",
    "            '2020-04-01',format='%Y-%m-%d').dayofyear - self.start_date.dayofyear\n",
    "        self.initial_people = people.copy() #detected people only\n",
    "        self.Reff = Reff\n",
    "        self.alpha_i = alpha_i\n",
    "        self.gam_list = gam_list\n",
    "        self.ps_list = ps_list#beta.rvs(7,3,size=1000)\n",
    "        self.qi_list = qi_list\n",
    "        self.qa_list = qa_list\n",
    "        self.qs_list = qs_list\n",
    "        self.k = k\n",
    "        self.qua_ai = qua_ai\n",
    "        self.qua_qi_factor = qua_qi_factor\n",
    "        self.qua_qs_factor=qua_qs_factor\n",
    "\n",
    "        self.forecast_R = forecast_R\n",
    "        self.R_I = R_I\n",
    "        np.random.seed(1)\n",
    "        #self.max_cases = 100000\n",
    "\n",
    "        self.forecast_date = pd.to_datetime(\n",
    "            forecast_date,format='%Y-%m-%d').dayofyear - self.start_date.dayofyear\n",
    "\n",
    "        self.Reff_file_date = Reff_file_date\n",
    "        self.cross_border_state = cross_border_state\n",
    "        self.cases_file_date = cases_file_date\n",
    "\n",
    "        if self.cross_border_state is not None:\n",
    "            self.travel_prob = self.p_travel()\n",
    "            self.travel_cases_after = 0\n",
    "            #placeholders for run_state script \n",
    "            self.cross_border_seeds = np.zeros(shape=(1,2),dtype=int)\n",
    "            self.cross_border_state_cases = np.zeros_like(self.cross_border_seeds)\n",
    "\n",
    "        if test_campaign_date is not None:\n",
    "            self.test_campaign_date = pd.to_datetime(\n",
    "                test_campaign_date,format='%Y-%m-%d').dayofyear - self.start_date.dayofyear\n",
    "            self.test_campaign_factor = test_campaign_factor\n",
    "        else:\n",
    "            self.test_campaign_date = None\n",
    "        #import model parameters\n",
    "        self.a_dict = {\n",
    "            'ACT': {\n",
    "                1:2,\n",
    "                2:22,\n",
    "                3:31*1.3,\n",
    "                4:17,\n",
    "                5:15,\n",
    "                6:3,\n",
    "            },\n",
    "            'NSW': {\n",
    "                1: 90,\n",
    "                2: 408,\n",
    "                3: 694*1.3,\n",
    "                4: 380,\n",
    "                5: 312,\n",
    "                6: 276,\n",
    "            },\n",
    "            'NT': {\n",
    "                1: 3,\n",
    "                2: 4,\n",
    "                3: 7*1.3,\n",
    "                4: 9,\n",
    "                5: 6,\n",
    "                6: 4,\n",
    "            },\n",
    "            'QLD': {\n",
    "                1:61,\n",
    "                2:190,\n",
    "                3:305*1.3,\n",
    "                4:162,\n",
    "                5:87,\n",
    "                6:25,\n",
    "            },\n",
    "            'SA': {\n",
    "                1:13,\n",
    "                2:68,\n",
    "                3:115*1.3,\n",
    "                4:67,\n",
    "                5:27,\n",
    "                6:6\n",
    "            },\n",
    "            'TAS':{\n",
    "                1:6,\n",
    "                2:14,\n",
    "                3:32*1.3,\n",
    "                4:19,\n",
    "                5:11,\n",
    "                6:2,\n",
    "            },\n",
    "            'VIC': {\n",
    "                1:62,\n",
    "                2:208,\n",
    "                3:255*1.3,\n",
    "                4:157,\n",
    "                5:87,\n",
    "                6:188,\n",
    "            },\n",
    "            'WA': {\n",
    "                1:15,\n",
    "                2:73,\n",
    "                3:154*1.3,\n",
    "                4:115,\n",
    "                5:110,\n",
    "                6:78\n",
    "            },\n",
    "        }\n",
    "        #changes below also need to be changed in simulate\n",
    "        self.b_dict = {\n",
    "            1: 6.2,\n",
    "            2: 7.2,\n",
    "            3: 5.2,\n",
    "            4: 5.2,\n",
    "            5: 22.2,\n",
    "            6: 145.2 ## this needs to change for\n",
    "                    # each change in forecast date\n",
    "        }\n",
    "\n",
    "        dir_path = os.getcwd()\n",
    "        self.datapath = os.path.join(dir_path,'../../data/')\n",
    "\n",
    "\n",
    "        assert len(people) == sum(current), \"Number of people entered does not equal sum of counts in current status\"\n",
    "        \n",
    "    def generate_times(self,  i=2.5, j=1.25, m=1.2, n=1, size=10000):\n",
    "        \"\"\"\n",
    "        Generate large amount of gamma draws to save on simulation time later\n",
    "        \"\"\"\n",
    "\n",
    "        self.inf_times = 1 + np.random.gamma(i/j, j, size =size) #shape and scale\n",
    "        self.detect_times = 1 + np.random.gamma(m/n,n, size = size)\n",
    "\n",
    "        return None\n",
    "    \n",
    "\n",
    "    def iter_inf_time(self):\n",
    "        \"\"\"\n",
    "        access Next inf_time\n",
    "        \"\"\"\n",
    "        from itertools import cycle\n",
    "        for time in cycle(self.inf_times):\n",
    "            yield time\n",
    "    \n",
    "    def iter_detect_time(self):\n",
    "        \"\"\"\n",
    "        access Next detect_time\n",
    "        \"\"\"\n",
    "        from itertools import cycle\n",
    "        for time in cycle(self.detect_times):\n",
    "            yield time\n",
    "\n",
    "    def initialise_sim(self,curr_time=0):\n",
    "        \"\"\"\n",
    "        Given some number of cases in self.initial_state (copied),\n",
    "        simulate undetected cases in each category and their \n",
    "        infectious times. Updates self.current for each person.\n",
    "        \"\"\"\n",
    "        from math import ceil\n",
    "        if curr_time ==0:\n",
    "            \n",
    "            #grab a sample from parameter lists\n",
    "            self.qs = self.choose_random_item(self.qs_list)\n",
    "            self.qa = self.choose_random_item(self.qa_list)\n",
    "            #resample qa until it is less than self.qs\n",
    "            while self.qa>=self.qs:\n",
    "                self.qa = self.choose_random_item(self.qa_list)\n",
    "            self.qi = self.choose_random_item(self.qi_list)\n",
    "            self.gam = self.choose_random_item(self.gam_list)\n",
    "            \n",
    "            self.ps = self.choose_random_item(self.ps_list)\n",
    "            self.alpha_s = 1/(self.ps + self.gam*(1-self.ps))\n",
    "            self.alpha_a = self.gam * self.alpha_s\n",
    "            self.current = self.initial_state.copy()\n",
    "            self.people = self.initial_people.copy()\n",
    "\n",
    "            #N samples for each of infection and detection times\n",
    "            #Grab now and iterate through samples to save simulation\n",
    "            self.generate_times(size=10000)\n",
    "            self.get_inf_time = self.iter_inf_time()\n",
    "            self.get_detect_time = self.iter_detect_time()\n",
    "\n",
    "            #counters for terminating early\n",
    "            self.inf_backcast_counter = 0\n",
    "            self.inf_forecast_counter = 0\n",
    "\n",
    "            #assign infection time to those discovered\n",
    "            # obs time is day =0\n",
    "            for person in self.people.keys():\n",
    "                self.people[person].infection_time = -1*next(self.get_inf_time)\n",
    "        else:\n",
    "            #reinitialising, so actual people need times\n",
    "            #assume all symptomatic\n",
    "            prob_symp_given_detect = self.qs*self.ps/(\n",
    "                self.qs*self.ps + self.qa*(1-self.ps)\n",
    "            )\n",
    "            num_symp = binom.rvs(n=int(self.current[2]), p=prob_symp_given_detect)\n",
    "            for person in range(int(self.current[2])):\n",
    "                self.infected_queue.append(len(self.people))\n",
    "                \n",
    "                inf_time = next(self.get_inf_time)\n",
    "                detection_time = next(self.get_detect_time)\n",
    "                if person <- num_symp:\n",
    "                    new_person = Person(-1, \n",
    "                    curr_time-1*detection_time ,\n",
    "                    curr_time, 1, 'S')\n",
    "                else:\n",
    "                    new_person = Person(-1, \n",
    "                    curr_time-1*detection_time ,\n",
    "                    curr_time, 1, 'A')\n",
    "                \n",
    "                self.people[len(self.people)] = new_person\n",
    "                \n",
    "                #self.cases[max(0,ceil(new_person.infection_time)), 2] +=1\n",
    "                \n",
    "\n",
    "        #num undetected is nbinom (num failures given num detected)\n",
    "        if self.current[2]==0:\n",
    "            num_undetected_s = nbinom.rvs(1,self.qs*self.qua_qs_factor)\n",
    "        else:\n",
    "            num_undetected_s = nbinom.rvs(self.current[2],self.qs*self.qua_qs_factor)\n",
    "        \n",
    "        if self.current[0]==0:\n",
    "            num_undetected_i = nbinom.rvs(1,self.qs*self.qua_qs_factor)\n",
    "        else:\n",
    "            num_undetected_i = nbinom.rvs(self.current[0], self.qi*self.qua_qi_factor)\n",
    "\n",
    "        total_s = num_undetected_s + self.current[2]\n",
    "\n",
    "        #infer some non detected asymp at initialisation\n",
    "        if total_s==0:\n",
    "            num_undetected_a = nbinom.rvs(1, self.ps)\n",
    "        else:\n",
    "            num_undetected_a = nbinom.rvs(total_s, self.ps)\n",
    "\n",
    "        #simulate cases that will be detected within the next week\n",
    "        #for n in range(1,8):\n",
    "            #just symptomatic?\n",
    "            #self.people[len(self.people)] = Person(0, -1*next(self.get_inf_time) , n, 0, 'S')\n",
    "        if curr_time==0:\n",
    "            #Add each undetected case into people\n",
    "            for n in range(num_undetected_i):\n",
    "                self.people[len(self.people)] = Person(0, curr_time-1*next(self.get_inf_time) , 0, 0, 'I')\n",
    "                self.current[0] +=1\n",
    "            for n in range(num_undetected_a):\n",
    "                self.people[len(self.people)] = Person(0, curr_time-1*next(self.get_inf_time) , 0, 0, 'A')\n",
    "                self.current[1] +=1\n",
    "            for n in range(num_undetected_s):\n",
    "                self.people[len(self.people)] = Person(0, curr_time-1*next(self.get_inf_time) , 0, 0, 'S')\n",
    "                self.current[2] +=1\n",
    "        else:\n",
    "            #reinitialised, so add these cases back onto cases\n",
    "             #Add each undetected case into people\n",
    "            for n in range(num_undetected_i):\n",
    "                new_person = Person(-1, curr_time-1*next(self.get_inf_time) , 0, 0, 'I')\n",
    "                self.infected_queue.append(len(self.people))\n",
    "                self.people[len(self.people)] = new_person\n",
    "                self.cases[max(0,ceil(new_person.infection_time)),0] +=1\n",
    "            for n in range(num_undetected_a):\n",
    "                new_person = Person(-1, curr_time-1*next(self.get_inf_time) , 0, 0, 'A')\n",
    "                self.infected_queue.append(len(self.people))\n",
    "                self.people[len(self.people)] = new_person\n",
    "                self.cases[max(0,ceil(new_person.infection_time)),1] +=1\n",
    "            for n in range(num_undetected_s):\n",
    "                new_person = Person(-1, curr_time-1*next(self.get_inf_time) , 0, 0, 'S')\n",
    "                self.infected_queue.append(len(self.people))\n",
    "                self.people[len(self.people)] = new_person\n",
    "                self.cases[max(0,ceil(new_person.infection_time)),2] +=1\n",
    "            \n",
    "        return None\n",
    "\n",
    "    def read_in_Reff(self):\n",
    "        \"\"\"\n",
    "        Read in Reff csv from Price et al 2020. Originals are in RDS, are converted to csv in R script\n",
    "        \"\"\"\n",
    "        import pandas as pd\n",
    "        #df= pd.read_csv(self.datapath+'R_eff_2020_04_23.csv', parse_dates=['date'])\n",
    "        if self.cross_border_state is not None:\n",
    "            states = [self.state,self.cross_border_state]\n",
    "        else:\n",
    "            states=[self.state]\n",
    "        \n",
    "\n",
    "        if self.forecast_R is not None:\n",
    "            if self.Reff_file_date is None:\n",
    "                import glob, os\n",
    "\n",
    "                list_of_files = glob.glob(self.datapath+'soc_mob_R*.h5') \n",
    "                latest_file = max(list_of_files, key=os.path.getctime)\n",
    "                print(\"Using file \"+latest_file)\n",
    "                df_forecast = pd.read_hdf(latest_file,\n",
    "            key='Reff')\n",
    "            else:\n",
    "                df_forecast = pd.read_hdf(self.datapath+'soc_mob_R'+self.Reff_file_date+'.h5',\n",
    "            key='Reff')\n",
    "            num_days = df_forecast.loc[\n",
    "                (df_forecast.type=='R_L')&(df_forecast.state==self.state)].shape[0]\n",
    "            if self.R_I is not None:\n",
    "                self.R_I = df_forecast.loc[\n",
    "                    (df_forecast.type=='R_I')&\n",
    "                    (df_forecast.state==self.state),\n",
    "                    [i for i in range(1000)]].values[0,:]\n",
    "\n",
    "            #R_L here \n",
    "            df_forecast = df_forecast.loc[df_forecast.type==self.forecast_R]\n",
    "\n",
    "            #df = pd.concat([\n",
    "            #            df.drop(['type','date_onset','confidence',\n",
    "            #                 'bottom','top','mean_window','prob_control',\n",
    "            #                'sd_window'],axis=1),\n",
    "            #            df_forecast.drop(['type'],axis=1)\n",
    "            #                ])\n",
    "            \n",
    "           #df = df.drop_duplicates(['state','date'],keep='last')\n",
    "            df = df_forecast\n",
    "            df = df.set_index(['state','date'])\n",
    "        \n",
    "        Reff_lookupdist ={}\n",
    "\n",
    "        for state in states:\n",
    "            Reff_lookupstate = {}\n",
    "            if self.forecast_R =='R_L':\n",
    "                dfReff_dict = df.loc[state,[0,1]].to_dict(orient='index')\n",
    "\n",
    "                for key, stats in dfReff_dict.items():\n",
    "                    #instead of mean and std, take all columns as samples of Reff\n",
    "                    #convert key to days since start date for easier indexing\n",
    "                    newkey = key.dayofyear - self.start_date.dayofyear\n",
    "\n",
    "                    Reff_lookupstate[newkey] = df.loc[(state,key),\n",
    "                    [i for i in range(1000)]].values\n",
    "\n",
    "            else:\n",
    "                #R_L0\n",
    "                for day in range(num_days):\n",
    "                    Reff_lookupstate[day] = df.loc[state, [i for i in range(1000)]].values[0]\n",
    "\n",
    "\n",
    "            #Nested dict with key to state, then key to date\n",
    "            Reff_lookupdist[state] = Reff_lookupstate\n",
    "\n",
    "        if self.cross_border_state is not None:\n",
    "            self.Reff_travel = Reff_lookupdist[self.cross_border_state]\n",
    "        \n",
    "        self.Reff = Reff_lookupdist[self.state]\n",
    "        return None\n",
    "    \n",
    "    def choose_random_item(self, items,weights=None):\n",
    "        from numpy.random import random\n",
    "        if weights is None:\n",
    "            #Create uniform weights\n",
    "            weights = [1/len(items)] * len(items)\n",
    "        r = random()\n",
    "        for i,item in enumerate(items):\n",
    "            r-= weights[i]\n",
    "            if r <0:\n",
    "                return item\n",
    "        \n",
    "            \n",
    "    def new_symp_cases(self,num_new_cases:int):\n",
    "        \"\"\"\n",
    "        Given number of new cases generated, assign them to symptomatic (S) with probability ps\n",
    "        \"\"\"\n",
    "        #repeated Bernoulli trials is a Binomial (assuming independence of development of symptoms)\n",
    "        \n",
    "        symp_cases = binom.rvs(n=num_new_cases, p=self.ps)\n",
    "\n",
    "        return symp_cases\n",
    "    \n",
    "    def generate_new_cases(self,parent_key, Reff,k,travel=True):\n",
    "        \"\"\"\n",
    "        Generate offspring for each parent, check if they travel\n",
    "        \"\"\"\n",
    "        \n",
    "        from math import ceil\n",
    "        from numpy.random import random\n",
    "\n",
    "    #check parent category   \n",
    "        if self.people[parent_key].category=='S':\n",
    "            num_offspring = nbinom.rvs(n=k,p= 1- self.alpha_s*Reff/(self.alpha_s*Reff + k))\n",
    "        elif self.people[parent_key].category=='A':\n",
    "            num_offspring = nbinom.rvs(n=k, p = 1- self.alpha_a*Reff/(self.alpha_a*Reff + k))\n",
    "        else:\n",
    "            #Is imported\n",
    "            if self.R_I is not None:\n",
    "                #if splitting imported from local, change Reff to R_I \n",
    "                Reff = self.choose_random_item(self.R_I)\n",
    "            if self.people[parent_key].infection_time < self.quarantine_change_date:\n",
    "                #factor of 3 times infectiousness prequarantine changes\n",
    "\n",
    "                num_offspring = nbinom.rvs(n=k, p = 1- self.qua_ai*Reff/(self.qua_ai*Reff + k))\n",
    "            else:\n",
    "                num_offspring = nbinom.rvs(n=k, p = 1- self.alpha_i*Reff/(self.alpha_i*Reff + k))\n",
    "        \n",
    "        if num_offspring >0:  \n",
    "            \n",
    "            num_sympcases = self.new_symp_cases(num_offspring)\n",
    "            if self.people[parent_key].category=='A':\n",
    "                child_times = []\n",
    "            for new_case in range(num_offspring):\n",
    "                #define each offspring\n",
    "                \n",
    "                inf_time = self.people[parent_key].infection_time + next(self.get_inf_time)\n",
    "               # LAURA\n",
    "                # print(inf_time)\n",
    "                # print(self.forecast_date)\n",
    "                \n",
    "                # Laura\n",
    "                # add an action_time = 0 when an offspring is first examined:\n",
    "                action_time = 0\n",
    "\n",
    "                if inf_time > self.forecast_date:\n",
    "                    self.inf_forecast_counter +=1\n",
    "                    if travel:\n",
    "                        if self.cross_border_state is not None:\n",
    "                        #check if SA person\n",
    "                            if random() < self.travel_prob:\n",
    "                                if ceil(inf_time) <= self.cases.shape[0]:\n",
    "                                    self.cross_border_state_cases[max(0,ceil(inf_time)-1),self.num_of_sim] += 1\n",
    "                                    detection_rv = random()\n",
    "                                    detect_time = 0 #give 0 by default, fill in if passes\n",
    "                            \n",
    "                                    recovery_time = 0 #for now not tracking recoveries\n",
    "                        \n",
    "                                    if new_case <= num_sympcases-1: #minus 1 as new_case ranges from 0 to num_offspring-1 \n",
    "                                        #first num_sympcases are symnptomatic, rest are asymptomatic\n",
    "                                        category = 'S'                                 \n",
    "                                        if detection_rv < self.qs:\n",
    "                                            #case detected\n",
    "                                            detect_time = inf_time + next(self.get_detect_time)\n",
    "\n",
    "                                    else:\n",
    "                                        category = 'A'\n",
    "                                        detect_time = 0\n",
    "                                        if detection_rv < self.qa:\n",
    "                                            #case detected\n",
    "                                            detect_time = inf_time + next(self.get_detect_time)\n",
    "                                    self.people[len(self.people)] = Person(parent_key, inf_time, detect_time,recovery_time, category)\n",
    "                                    self.cross_border_sim(len(self.people)-1,ceil(inf_time))\n",
    "                                    #skip simulating this offspring in VIC\n",
    "                                    #continue\n",
    "                                else:\n",
    "                                    #cross border seed happened after forecast\n",
    "                                    self.travel_cases_after +=1\n",
    "                else:\n",
    "                    self.inf_backcast_counter +=1\n",
    "                #normal case within state\n",
    "                if self.people[parent_key].category=='A':\n",
    "                    child_times.append(ceil(inf_time))\n",
    "                if ceil(inf_time) > self.cases.shape[0]:\n",
    "                    #new infection exceeds the simulation time, not recorded\n",
    "                    self.cases_after = self.cases_after + 1                \n",
    "                else:\n",
    "                    #within forecast time\n",
    "                    detection_rv = random()\n",
    "                    detect_time = inf_time + next(self.get_detect_time)\n",
    "                        \n",
    "                    isdetected = 0 \n",
    "                    \n",
    "                    if new_case <= num_sympcases-1: #minus 1 as new_case ranges from 0 to num_offspring-1 \n",
    "                        #first num_sympcases are symnptomatic, rest are asymptomatic\n",
    "                        category = 'S'\n",
    "                        self.cases[max(0,ceil(inf_time)-1),2] += 1\n",
    "                        \n",
    "                        if self.test_campaign_date is not None:\n",
    "                            #see if case is during a testing campaign\n",
    "                            if inf_time <self.test_campaign_date:\n",
    "                                detect_prob = self.qs\n",
    "                            else:\n",
    "                                detect_prob = min(0.95,self.qs*self.test_campaign_factor)\n",
    "                        else:\n",
    "                            detect_prob = self.qs\n",
    "                        if detection_rv < detect_prob:\n",
    "                            #case detected\n",
    "                            isdetected=1\n",
    "                            # Laura\n",
    "                            # if parent is undetected, assign a new time to action \n",
    "                            if self.people[parent_key].detected==0:\n",
    "                                action_time = detect_time + gamma(t_a_shape,t_a_scale)\n",
    "                            if detect_time < self.cases.shape[0]:\n",
    "                                self.observed_cases[max(0,ceil(detect_time)-1),2] += 1\n",
    "\n",
    "                    else:\n",
    "                        category = 'A'\n",
    "                        self.cases[max(0,ceil(inf_time)-1),1] += 1\n",
    "                        #detect_time = 0\n",
    "                        if self.test_campaign_date is not None:\n",
    "                        #see if case is during a testing campaign\n",
    "                            if inf_time <self.test_campaign_date:\n",
    "                                detect_prob = self.qa\n",
    "                            else:\n",
    "                                detect_prob = min(0.95,self.qa*self.test_campaign_factor)\n",
    "                        else:\n",
    "                            detect_prob=self.qa\n",
    "                        if detection_rv < detect_prob:\n",
    "                            #case detected\n",
    "                            isdetected=1\n",
    "                            #detect_time = inf_time + next(self.get_detect_time)\n",
    "                            # Laura \n",
    "                            # Get absolute action time, \n",
    "                            # if parent is not detected, assign an action time \n",
    "                            # action_time = self.people[parent_key].detection_time + \n",
    "                            # 2* draw from distrubtion\n",
    "                            if self.people[parent_key].detected==0:\n",
    "                                action_time = detect_time + 2*gamma(t_a_shape,t_a_scale)\n",
    "                            if detect_time < self.cases.shape[0]:\n",
    "                                self.observed_cases[max(0,ceil(detect_time)-1),1] += 1\n",
    "\n",
    "                    # Laura \n",
    "                    #add new infected to queue\n",
    "                    # contact trace 2=1 day before parent's detection time\n",
    "                    if self.people[parent_key].detected==1:\n",
    "                        #only check contact tracing if parent was detected\n",
    "                        \n",
    "                        if inf_time < self.people[parent_key].detection_time - DAYS:\n",
    "                            \n",
    "                            self.infected_queue.append(len(self.people))\n",
    "                            \n",
    "                        #elif  (self.people[parent_key].detection_time - DAYS) < inf_time < (self.people[parent_key].action_time):\n",
    "                        # elif ((self.people[parent_key].detection_time - DAYS) < inf_time) and (inf_time < (self.people[parent_key].action_time)):   \n",
    "                        elif inf_time < (self.people[parent_key].action_time):   \n",
    "                            \n",
    "                            x_rn = random()\n",
    "                            if x_rn <= p_c:\n",
    "                        \n",
    "                                action_time = self.people[parent_key].action_time\n",
    "                                self.infected_queue.append(len(self.people))\n",
    "                            \n",
    "                        # else assign new time to action.\n",
    "                        # need to add if de\n",
    "                            else:\n",
    "                                action_time = inf_time + gamma(t_a_shape,t_a_scale)\n",
    "                                self.infected_queue.append(len(self.people))\n",
    "                                \n",
    "                    else:\n",
    "                        #parent undetected\n",
    "                        self.infected_queue.append(len(self.people))\n",
    "                        \n",
    "\n",
    "                    #add person to tracked people\n",
    "                    # Laura # add action_time when recording\n",
    "                    self.people[len(self.people)] = Person(parent_key, inf_time, detect_time,isdetected, category,action_time)\n",
    "\n",
    "            if travel:\n",
    "                #for parent, check their cross border travel\n",
    "                if self.cross_border_state is not None:\n",
    "                    #Run cross border sim across children\n",
    "                    inf_time = self.people[parent_key].infection_time\n",
    "\n",
    "                    detect_time = self.people[parent_key].detection_time\n",
    "\n",
    "                    if self.people[parent_key].infection_time>self.forecast_date:\n",
    "                        #check it is after forecast date but before\n",
    "                        #end date\n",
    "                        if ceil(inf_time)-1 < self.cases.shape[0]:\n",
    "                            #check if travel\n",
    "                            #symptomatic people here\n",
    "                            pre_symp_time = inf_time\n",
    "                            while pre_symp_time < detect_time:\n",
    "                                travel_rv = random()\n",
    "                                if travel_rv<self.travel_prob:\n",
    "                                    #travelled\n",
    "                                    ## did they infect?\n",
    "                                    #symptomatic\n",
    "                                    self.cross_border_sim(parent_key,ceil(pre_symp_time))\n",
    "\n",
    "                                #can travel more than once\n",
    "                                pre_symp_time +=1 #move forward a day\n",
    "                                if pre_symp_time>self.cases.shape[0]:\n",
    "                                    break\n",
    "                            if detect_time==0:\n",
    "                                #asymptomatics\n",
    "                                if self.people[parent_key].category=='A':\n",
    "                                    for pre_symp_time in child_times:\n",
    "                                        if pre_symp_time< self.cases.shape[0] -1:\n",
    "                                            #only care if still within forecast time\n",
    "                                            travel_rv = random()\n",
    "                                            if travel_rv<self.travel_prob:\n",
    "                                            #travelled\n",
    "                                            ## did they infect?\n",
    "                                                self.cross_border_sim(parent_key,ceil(pre_symp_time))\n",
    "\n",
    "                                            #remove case from original state?\n",
    "        return None\n",
    "    \n",
    "    def cases_detected(self,new_cases):\n",
    "        \"\"\"\n",
    "        Given a tuple of new_cases generated, return the number of cases detected\n",
    "        \"\"\"\n",
    "        #Number of detected cases in each class is Binomial with p = q_j\n",
    "\n",
    "        i_detected = binom.rvs(n=new_cases[0],p=self.qi)\n",
    "        a_detected = binom.rvs(n=new_cases[1],p=self.qa)\n",
    "        s_detected = binom.rvs(n=new_cases[2],p=self.qs)\n",
    "\n",
    "        return i_detected, a_detected, s_detected\n",
    "    \n",
    "    def import_arrival(self,period,size=1):\n",
    "        \"\"\"\n",
    "        Poisson likelihood of arrivals of imported cases, with a Gamma\n",
    "        prior on the mean of Poisson, results in a posterior predictive\n",
    "        distribution of imported cases a Neg Binom\n",
    "        \"\"\"\n",
    "        a = self.a_dict[self.state][period]\n",
    "        b = self.b_dict[period]\n",
    "        if size==1:\n",
    "            return nbinom.rvs(a, 1-1/(b+1))\n",
    "        else:\n",
    "            return nbinom.rvs(a, 1-1/(b+1),size=size)\n",
    "\n",
    "    def simulate(self, end_time,sim,seed):\n",
    "        \"\"\"\n",
    "        Simulate forward until end_time\n",
    "        \"\"\"\n",
    "        from collections import deque\n",
    "        from math import ceil\n",
    "        import gc\n",
    "        np.random.seed(seed)\n",
    "        self.num_of_sim = sim\n",
    "        #generate storage for cases\n",
    "        self.cases = np.zeros(shape=(end_time, 3),dtype=float)\n",
    "        self.observed_cases = np.zeros_like(self.cases)\n",
    "        \n",
    "        self.observed_cases[0,:] = self.initial_state.copy()\n",
    "\n",
    "        #Initalise undetected cases and add them to current\n",
    "        self.initialise_sim()\n",
    "        #number of cases after end time\n",
    "        self.cases_after = 0 #gets incremented in generate new cases\n",
    "\n",
    "        #Record day 0 cases\n",
    "        self.cases[0,:] = self.current.copy() \n",
    "        # Generate imported cases\n",
    "        num_days={\n",
    "            1: 6,\n",
    "            2: 8,\n",
    "            3: 4,\n",
    "            4: 5,\n",
    "            5: 22,#min(end_time - self.quarantine_change_date -7, 24 ),\n",
    "            6: max(0,end_time- 6-8-4-5-22),\n",
    "        }\n",
    "        qi = {\n",
    "            1:self.qi *self.qua_qi_factor,\n",
    "            2:self.qi,\n",
    "            3:self.qi,\n",
    "            4:0.95,\n",
    "            5:0.98,\n",
    "            6:0.98,\n",
    "        }\n",
    "        new_imports = []\n",
    "        unobs_imports =[]\n",
    "        for period in range(1,7): \n",
    "            ##ADDED continue TO SKIP THIS FOR LB\n",
    "            continue\n",
    "            ######\n",
    "            obs_cases = self.import_arrival(\n",
    "                period=period, size=num_days[period])\n",
    "            #generate undetected people\n",
    "            #if obs_cases includes 0.... then add one for nbinom\n",
    "            nbinom_var = [o+1 if o ==0 else o for o in obs_cases ]\n",
    "            unobs = nbinom.rvs(nbinom_var, p=qi[period])#modify qi here\n",
    "            unobs_imports.extend(unobs)\n",
    "            new_imports.extend(obs_cases + unobs)\n",
    "\n",
    "        for day, imports in enumerate(new_imports):\n",
    "            ##ADDED continue TO SKIP THIS FOR LB\n",
    "            continue\n",
    "            #######\n",
    "            \n",
    "            self.cases[day,0] = imports\n",
    "            for n in range(imports):\n",
    "                #Generate people\n",
    "                if n - unobs_imports[day]>=0:\n",
    "                    #number of observed people\n",
    "                    new_person = Person(0,day,day +next(self.get_detect_time),1,'I')\n",
    "                    self.people[len(self.people)] = new_person\n",
    "                    if new_person.detection_time <= end_time:\n",
    "                        self.observed_cases[max(0,ceil(new_person.detection_time)-1),0] +=1\n",
    "                else:\n",
    "                    #unobserved people\n",
    "                    new_person = Person(0,day,0,0,'I')\n",
    "                    self.people[len(self.people)] = new_person\n",
    "                    if day <= end_time:\n",
    "                        self.cases[max(0,day-1), 0] +=1\n",
    "         #####\n",
    "\n",
    "        #Create queue for infected people\n",
    "        self.infected_queue = deque()\n",
    "        #Assign people to infected queue\n",
    "        for key, person in self.people.items():\n",
    "            #add to the queue\n",
    "            self.infected_queue.append(key)\n",
    "            #Record their times\n",
    "            if person.infection_time> end_time:\n",
    "                #initial undetected cases have slim chance to be infected \n",
    "                #after end_time\n",
    "                if person.category!='I':\n",
    "                    #imports shouldn't count for extinction counts\n",
    "                    self.cases_after +=1\n",
    "                    print(\"cases after at initialisation\")\n",
    "            #else:\n",
    "            #    if person.category=='S':\n",
    "            #        self.cases[max(0,ceil(person.infection_time)),2] +=1\n",
    "            #        if (person.detection_time < end_time) & (person.detection_time!=0):\n",
    "            #            self.observed_cases[max(0,ceil(person.detection_time)), 2] +=1\n",
    "            #    elif person.category=='I':\n",
    "                    #Imports recorded on creation in sim\n",
    "            #        continue\n",
    "            #    elif person.category=='A':\n",
    "            #        self.cases[max(0,ceil(person.infection_time)),1] +=1\n",
    "            #        if (person.detection_time < end_time) & (person.detection_time!=0):\n",
    "            #            self.observed_cases[max(0,ceil(person.detection_time)), 1] +=1\n",
    "            #    else:\n",
    "                    print(\"ERROR: not right category\")\n",
    "\n",
    "        #Record initial inferred obs including importations.\n",
    "        self.inferred_initial_obs = self.observed_cases[0,:].copy() \n",
    "        #print(self.inferred_initial_obs, self.current)\n",
    "\n",
    "\n",
    "        # General simulation through time by proceeding through queue\n",
    "        # of infecteds\n",
    "        n_resim = 0\n",
    "        self.bad_sim = False\n",
    "        reinitialising_window = 0\n",
    "        self.daycount= 0\n",
    "        while len(self.infected_queue)>0:\n",
    "            day_end = self.people[self.infected_queue[0]].infection_time\n",
    "            if day_end < self.forecast_date:\n",
    "                if self.inf_backcast_counter> self.max_backcast_cases:\n",
    "                    print(\"Sim \"+str(self.num_of_sim\n",
    "                    )+\" in \"+self.state+\" has > \"+str(self.max_backcast_cases)+\" cases in backcast. Ending\")\n",
    "                    self.num_too_many+=1\n",
    "                    self.bad_sim = True\n",
    "                    break\n",
    "            else:\n",
    "                #check max cases for after forecast date\n",
    "                if self.inf_forecast_counter>self.max_cases:\n",
    "                    #hold value forever\n",
    "                    if day_end < self.cases.shape[0]-1:\n",
    "                        self.cases[ceil(day_end):,2] = self.cases[ceil(day_end)-2,2]\n",
    "\n",
    "                        self.observed_cases[ceil(day_end):,2] = self.observed_cases[ceil(day_end)-2,2]\n",
    "                    else:\n",
    "                        self.cases_after +=1\n",
    "                \n",
    "                    print(\"Sim \"+str(self.num_of_sim\n",
    "                        )+\" in \"+self.state+\" has >\"+str(self.max_cases)+\" cases in forecast period.\")\n",
    "                    self.num_too_many+=1\n",
    "                    break\n",
    "\n",
    "            \n",
    "            ## stop if parent infection time greater than end time\n",
    "            if self.people[self.infected_queue[0]].infection_time >end_time:\n",
    "                self.infected_queue.popleft()\n",
    "                print(\"queue had someone exceed end_time!!\")\n",
    "            else:\n",
    "                \n",
    "                #take approproate Reff based on parent's infection time\n",
    "                curr_time = self.people[self.infected_queue[0]].infection_time\n",
    "                if type(self.Reff)==int:\n",
    "                    Reff = 1\n",
    "                    print(\"using flat Reff\")\n",
    "                elif type(self.Reff)==dict:\n",
    "                    while True:\n",
    "                        #sometimes initial cases infection time is pre\n",
    "                        #Reff data, so take the earliest one\n",
    "                        try:\n",
    "                            Reff = self.choose_random_item(self.Reff[ceil(curr_time)-1])\n",
    "                        except KeyError:\n",
    "                            if curr_time>0:\n",
    "                                print(\"Unable to find Reff for this parent at time: %.2f\" % curr_time)\n",
    "                                raise KeyError\n",
    "                            curr_time +=1\n",
    "                            continue\n",
    "                        break\n",
    "                #generate new cases with times\n",
    "                parent_key = self.infected_queue.popleft()\n",
    "                #recorded within generate new cases\n",
    "                self.generate_new_cases(parent_key,Reff=Reff,k = self.k) \n",
    "        #self.people.clear()\n",
    "        if self.bad_sim ==False:\n",
    "            #Check simulation for discrepancies\n",
    "            for day in range(end_time):\n",
    "                #each day runs through self.infected_queue\n",
    "                \n",
    "                ##ADDED continue TO SKIP THIS FOR LB\n",
    "                continue\n",
    "                #######\n",
    "                \n",
    "                missed_outbreak = self.data_check(day) #True or False\n",
    "                if missed_outbreak:\n",
    "                    self.daycount +=1                \n",
    "                    if self.daycount >= reinitialising_window:\n",
    "                        n_resim +=1\n",
    "                        #print(\"Local outbreak in \"+self.state+\" not simulated on day %i\" % day)\n",
    "                        #cases to add\n",
    "                        #treat current like empty list\n",
    "                        self.current[2] = max(0,self.actual[day] - sum(self.observed_cases[day,1:])) \n",
    "                        self.current[2] += max(0,self.actual[day-1] - sum(self.observed_cases[day-1,1:]))\n",
    "                        self.current[2] += max(0,self.actual[day-2] - sum(self.observed_cases[day-2,1:]))\n",
    "\n",
    "                        #how many cases are symp to asymp\n",
    "                        prob_symp_given_detect = self.qs*self.ps/(\n",
    "                        self.qs*self.ps + self.qa*(1-self.ps)\n",
    "                        )\n",
    "                        num_symp = binom.rvs(n=int(self.current[2]), \n",
    "                            p=prob_symp_given_detect)\n",
    "                        #distribute observed cases over 3 days\n",
    "                         #Triangularly\n",
    "                        self.observed_cases[max(0,day),2] += num_symp//2\n",
    "                        self.cases[max(0,day),2] += num_symp//2\n",
    "\n",
    "                        self.observed_cases[max(0,day-1),2] += num_symp//3\n",
    "                        self.cases[max(0,day-1),2] += num_symp//3\n",
    "\n",
    "                        self.observed_cases[max(0,day-2),2] += num_symp//6\n",
    "                        self.cases[max(0,day-2),2] +=num_symp//6\n",
    "\n",
    "                        #add asymptomatic\n",
    "                        num_asymp = self.current[2] - num_symp\n",
    "                        self.observed_cases[max(0,day),2] += num_asymp//2\n",
    "                        self.cases[max(0,day),2] += num_asymp//2\n",
    "\n",
    "                        self.observed_cases[max(0,day-1),2] += num_asymp//3\n",
    "                        self.cases[max(0,day-1),2] += num_asymp//3\n",
    "\n",
    "                        self.observed_cases[max(0,day-2),2] += num_asymp//6\n",
    "                        self.cases[max(0,day-2),2] +=num_asymp//6\n",
    "\n",
    "                        self.initialise_sim(curr_time=day)\n",
    "                        #print(\"Reinitialising with %i new cases \"  % self.current[2] )\n",
    "\n",
    "                        #reset days to zero\n",
    "                        self.daycount = 0\n",
    "\n",
    "                if n_resim> 10:\n",
    "                    print(\"This sim reinitilaised %i times\" % n_resim)\n",
    "                    self.bad_sim = True\n",
    "                    n_resim = 0\n",
    "                    break\n",
    "                #Each check of day needs to simulate the cases before moving\n",
    "                # to next check, otherwise will be doubling up on undetecteds\n",
    "                while len(self.infected_queue)>0:\n",
    "                    day_end = self.people[self.infected_queue[0]].infection_time\n",
    "                    \n",
    "                    #check for exceeding max_cases\n",
    "                    if day_end <self.forecast_date:\n",
    "                        if self.inf_backcast_counter > self.max_backcast_cases:\n",
    "                            print(\"Sim \"+str(self.num_of_sim\n",
    "                            )+\" in \"+self.state+\" has > \"+str(self.max_backcast_cases)+\" cases in backcast. Ending\")\n",
    "                            self.num_too_many+=1\n",
    "                            self.bad_sim = True\n",
    "                            break\n",
    "                    else:\n",
    "                        if self.inf_forecast_counter> self.max_cases:\n",
    "                            \n",
    "                            self.cases[ceil(day_end):,2] = self.cases[ceil(day_end)-2,2]\n",
    "\n",
    "                            self.observed_cases[ceil(day_end):,2] = self.observed_cases[ceil(day_end)-2,2]\n",
    "                            print(\"Sim \"+str(self.num_of_sim\n",
    "                                )+\" in \"+self.state+\" has >\"+str(self.max_cases)+\" cases in forecast period.\")\n",
    "                            self.num_too_many+=1\n",
    "                            break\n",
    "                    ## stop if parent infection time greater than end time\n",
    "                    if self.people[self.infected_queue[0]].infection_time >end_time:\n",
    "                        personkey =self.infected_queue.popleft()\n",
    "                        print(\"queue had someone exceed end_time!!\")\n",
    "                    else:\n",
    "                        #take approproate Reff based on parent's infection time\n",
    "                        curr_time = self.people[self.infected_queue[0]].infection_time\n",
    "                        if type(self.Reff)==int:\n",
    "                            Reff = 2\n",
    "                        elif type(self.Reff)==dict:\n",
    "                            while True:\n",
    "                                #sometimes initial cases infection time is pre\n",
    "                                #Reff data, so take the earliest one\n",
    "                                try:\n",
    "                                    Reff = self.choose_random_item(self.Reff[ceil(curr_time)-1])\n",
    "                                except KeyError:\n",
    "                                    if curr_time>0:\n",
    "                                        print(\"Unable to find Reff for this parent at time: %.2f\" % curr_time)\n",
    "                                        raise KeyError\n",
    "                                    curr_time +=1\n",
    "                                    continue\n",
    "                                break\n",
    "                        #generate new cases with times\n",
    "                        parent_key = self.infected_queue.popleft()\n",
    "                        self.generate_new_cases(parent_key,Reff=Reff,k=self.k)\n",
    "                        #missed_outbreak = max(1,missed_outbreak*0.9)\n",
    "                else:\n",
    "                    #pass in here if while queue loop completes \n",
    "                    continue\n",
    "                #only reach here if while loop breaks, so break the data check\n",
    "                break\n",
    "                \n",
    "        #LB needs people recorded, do not clear this attribute\n",
    "        #self.people.clear()\n",
    "        gc.collect()\n",
    "        if self.bad_sim:\n",
    "            #return NaN arrays for all bad_sims\n",
    "            self.metric = np.nan\n",
    "            self.cumulative_cases = np.empty_like(self.cases)\n",
    "            self.cumulative_cases[:] = np.nan\n",
    "            return (self.cumulative_cases,self.cumulative_cases, {\n",
    "                'qs':self.qs,\n",
    "                'metric':self.metric,\n",
    "                'qa':self.qa,\n",
    "                'qi':self.qi,\n",
    "                'alpha_a':self.alpha_a,\n",
    "                'alpha_s':self.alpha_s,\n",
    "                #'accept':self.accept,\n",
    "                'ps':self.ps,\n",
    "                'bad_sim':self.bad_sim,\n",
    "                # Laura add\n",
    "                'Model_people':len(Model.people),\n",
    "                'cases_after':self.cases_after,\n",
    "                'travel_seeds': self.cross_border_seeds[:,self.num_of_sim],\n",
    "                'travel_induced_cases'+str(self.cross_border_state):self.cross_border_state_cases,\n",
    "                'num_of_sim':self.num_of_sim,\n",
    "            }\n",
    "            )\n",
    "        else:\n",
    "            #good sim\n",
    "\n",
    "            ## Perform metric for ABC\n",
    "            self.get_metric(end_time)\n",
    "\n",
    "            return (\n",
    "                self.cases.copy(), \n",
    "                self.observed_cases.copy(), {\n",
    "                'qs':self.qs,\n",
    "                'metric':self.metric,\n",
    "                'qa':self.qa,\n",
    "                'qi':self.qi,\n",
    "                'alpha_a':self.alpha_a,\n",
    "                'alpha_s':self.alpha_s,\n",
    "                #'accept':self.metric>=0.8,\n",
    "                'ps':self.ps,\n",
    "                'bad_sim':self.bad_sim,\n",
    "                # Laura add\n",
    "                'Model_people':len(Model.people),\n",
    "                'cases_after':self.cases_after,\n",
    "                'travel_seeds': self.cross_border_seeds[:,self.num_of_sim],\n",
    "                'travel_induced_cases'+str(self.cross_border_state):self.cross_border_state_cases[:,self.num_of_sim],\n",
    "                'num_of_sim':self.num_of_sim,\n",
    "            }\n",
    "            ) \n",
    "    \n",
    "    def simulate_many(self, end_time, n_sims):\n",
    "        \"\"\"\n",
    "        Simulate multiple times \n",
    "        \"\"\"\n",
    "        self.end_time = end_time\n",
    "        # Read in actual cases from NNDSS\n",
    "        self.read_in_cases()\n",
    "        import_sims = np.zeros(shape=(end_time, n_sims), dtype=float)\n",
    "        import_sims_obs = np.zeros_like(import_sims)\n",
    "        \n",
    "\n",
    "        import_inci = np.zeros_like(import_sims)\n",
    "        import_inci_obs = np.zeros_like(import_sims)\n",
    "\n",
    "        asymp_inci = np.zeros_like(import_sims)\n",
    "        asymp_inci_obs = np.zeros_like(import_sims)\n",
    "\n",
    "        symp_inci = np.zeros_like(import_sims)\n",
    "        symp_inci_obs = np.zeros_like(import_sims)\n",
    "\n",
    "        bad_sim = np.zeros(shape=(n_sims),dtype=int)\n",
    "\n",
    "        #ABC parameters\n",
    "        metrics = np.zeros(shape=(n_sims),dtype=float)\n",
    "        qs = np.zeros(shape=(n_sims),dtype=float)\n",
    "        qa = np.zeros_like(qs)\n",
    "        qi = np.zeros_like(qs)\n",
    "        alpha_a = np.zeros_like(qs)\n",
    "        alpha_s = np.zeros_like(qs)\n",
    "        accept = np.zeros_like(qs)\n",
    "        ps = np.zeros_like(qs)\n",
    "\n",
    "\n",
    "        #extinction prop\n",
    "        cases_after = np.empty_like(metrics) #dtype int\n",
    "        self.cross_border_seeds = np.zeros(shape=(end_time,n_sims),dtype=int)\n",
    "        self.cross_border_state_cases = np.zeros_like(self.cross_border_seeds)\n",
    "        self.num_bad_sims = 0\n",
    "        self.num_too_many = 0\n",
    "        for n in range(n_sims):\n",
    "            if n%(n_sims//10)==0:\n",
    "                print(\"{} simulation number %i of %i\".format(self.state) % (n,n_sims))\n",
    "            \n",
    "            inci, inci_obs, param_dict = self.simulate(end_time, n,n)\n",
    "            if self.bad_sim:\n",
    "                bad_sim[n] = 1\n",
    "                print(\"Sim \"+str(n)+\" of \"+self.state+\" is a bad sim\")\n",
    "                self.num_bad_sims +=1\n",
    "            else:\n",
    "                #good sims\n",
    "                ## record all parameters and metric\n",
    "                metrics[n] = self.metric\n",
    "                qs[n] = self.qs\n",
    "                qa[n] = self.qa\n",
    "                qi[n] = self.qi\n",
    "                alpha_a[n] = self.alpha_a\n",
    "                alpha_s[n] = self.alpha_s\n",
    "                accept[n] = int(self.metric>=0.8)\n",
    "                cases_after[n] = self.cases_after\n",
    "                ps[n] =self.ps\n",
    "            \n",
    "            \n",
    "\n",
    "            import_inci[:,n] = inci[:,0]\n",
    "            asymp_inci[:,n] = inci[:,1]\n",
    "            symp_inci[:,n] = inci[:,2]\n",
    "\n",
    "            import_inci_obs[:,n] = inci_obs[:,0]\n",
    "            asymp_inci_obs[:,n] = inci_obs[:,1]\n",
    "            symp_inci_obs[:,n] = inci_obs[:,2]\n",
    "\n",
    "        #Apply sim metric here and record\n",
    "        #dict of arrays n_days by sim columns\n",
    "        results = {\n",
    "            'imports_inci': import_inci,\n",
    "            'imports_inci_obs': import_inci_obs,\n",
    "            'asymp_inci': asymp_inci,\n",
    "            'asymp_inci_obs': asymp_inci_obs,\n",
    "            'symp_inci': symp_inci,\n",
    "            'symp_inci_obs': symp_inci_obs,\n",
    "            'total_inci_obs': symp_inci_obs + asymp_inci_obs,\n",
    "            'total_inci': symp_inci + asymp_inci,\n",
    "            'all_inci': symp_inci + asymp_inci + import_inci,\n",
    "            'bad_sim': bad_sim,\n",
    "            'metrics': metrics,\n",
    "            'accept': accept,\n",
    "            'qs':qs,\n",
    "            'qa':qa,\n",
    "            'qi':qi,\n",
    "            'alpha_a':alpha_a,\n",
    "            'alpha_s':alpha_s,\n",
    "            'cases_after':cases_after,\n",
    "            'travel_seeds': self.cross_border_seeds,\n",
    "            'travel_induced_cases'+str(self.cross_border_state):self.cross_border_state_cases,\n",
    "            'ps':ps,\n",
    "        }\n",
    "        \n",
    "        self.results = self.to_df(results)\n",
    "        print(\"Number of bad sims is %i\" % self.num_bad_sims)\n",
    "        print(\"Number of sims in \"+self.state\\\n",
    "            +\" exceeding \"+\\\n",
    "                str(self.max_cases//1000)+\"k cases is \"+str(self.num_too_many))\n",
    "        return self.state,self.results\n",
    "    \n",
    "\n",
    "    def to_df(self,results):\n",
    "        \"\"\"\n",
    "        Put results into a pandas dataframe and record as h5 format\n",
    "        \"\"\"\n",
    "        import pandas as pd\n",
    "\n",
    "        df_results = pd.DataFrame()\n",
    "        n_sims = results['symp_inci'].shape[1]\n",
    "        days = results['symp_inci'].shape[0]\n",
    "\n",
    "        sim_vars=['bad_sim','metrics','qs','qa','qi',\n",
    "        'accept','cases_after','alpha_a','alpha_s','ps'] \n",
    "\n",
    "        for key, item in results.items():\n",
    "            if key not in sim_vars:\n",
    "                df_results = df_results.append(\n",
    "                    pd.DataFrame(\n",
    "                        item.T,index=pd.MultiIndex.from_product([\n",
    "                            [key], range(n_sims)],\n",
    "                            names=['Category', 'sim']\n",
    "                            )\n",
    "                        )\n",
    "                    )\n",
    "        df_results.columns = pd.date_range(start = self.start_date,\n",
    "                            periods=days #num of days\n",
    "                        )\n",
    "        df_results.columns = [col.strftime('%Y-%m-%d') for \n",
    "                    col in df_results.columns]\n",
    "        #Record simulation variables \n",
    "        for var in sim_vars:       \n",
    "            df_results[var] = [results[var][sim] for cat,sim in df_results.index]\n",
    "\n",
    "        print(\"Saving results for state \"+self.state)\n",
    "        if self.forecast_R is None:\n",
    "            df_results.to_parquet(\n",
    "                \"./results/\"+self.state+self.start_date.strftime(\n",
    "                    format='%Y-%m-%d')+\"sim_results\"+str(n_sims)+\"days_\"+str(days)+\".parquet\",\n",
    "                    )\n",
    "        else:\n",
    "            df_results.to_parquet(\n",
    "                \"./results/\"+self.state+self.start_date.strftime(\n",
    "                    format='%Y-%m-%d')+\"sim_\"+self.forecast_R+str(n_sims)+\"days_\"+str(days)+\".parquet\",\n",
    "                    )\n",
    "\n",
    "        return df_results\n",
    "\n",
    "\n",
    "    def data_check(self,day):\n",
    "        \"\"\"\n",
    "        A metric to calculate how far the simulation is from the actual data\n",
    "        \"\"\"\n",
    "        try:\n",
    "            actual_3_day_total = 0\n",
    "            for i in range(3):\n",
    "                actual_3_day_total += self.actual[max(0,day-i)]\n",
    "            threshold = 10*max(1,sum(\n",
    "                self.observed_cases[\n",
    "                    max(0,day-2):day+1,2] + self.observed_cases[\n",
    "                        max(0,day-2):day+1,1]\n",
    "                )\n",
    "            )\n",
    "            if  actual_3_day_total > threshold:\n",
    "                return min(3,actual_3_day_total/threshold)\n",
    "            else:\n",
    "                #no outbreak missed\n",
    "                return False\n",
    "\n",
    "        except KeyError:\n",
    "            #print(\"No cases on day %i\" % day)\n",
    "            return False\n",
    "        \n",
    "    def get_metric(self,end_time,omega=0.2):\n",
    "        \"\"\"\n",
    "        Calculate the value of the metric of the current sim compared \n",
    "        to NNDSS data\n",
    "        \"\"\"\n",
    "\n",
    "        ##missing dates\n",
    "        #Deprecated now (DL 03/07/2020)\n",
    "        #missed_dates = [day for day in range(end_time) \n",
    "        #    if day not in self.actual.keys()]\n",
    "\n",
    "        self.actual_array = np.array([self.actual[day]\n",
    "        #if day not in missed_dates else 0 \n",
    "        for day in range(end_time) ])\n",
    "\n",
    "        #calculate case differences\n",
    "        #moving windows\n",
    "        sim_cases =self.observed_cases[\n",
    "            :len(self.actual_array),2] + \\\n",
    "                self.observed_cases[:\n",
    "                len(self.actual_array),1] #include asymp cases.\n",
    "        \n",
    "        #convolution with 1s should do cum sum \n",
    "        window = 7\n",
    "        sim_cases = np.convolve(sim_cases,\n",
    "            [1]*window,mode='valid')\n",
    "        actual_cum = np.convolve(self.actual_array,\n",
    "            [1]*window,mode='valid')\n",
    "        cases_diff = abs(sim_cases - actual_cum)\n",
    "        \n",
    "        #if sum(cases_diff) <= omega * sum(self.actual_array):\n",
    "            #cumulative diff passes, calculate metric\n",
    "\n",
    "            #sum over days number of times within omega of actual\n",
    "        self.metric = sum(\n",
    "            np.square(cases_diff)#,np.maximum(omega* actual_cum,7)\n",
    "            )\n",
    "        \n",
    "        self.metric = self.metric/(end_time-window) #max is end_time\n",
    "\n",
    "        return None\n",
    "    def read_in_cases(self):\n",
    "        \"\"\"\n",
    "        Read in NNDSS case data to measure incidence against simulation\n",
    "        \"\"\"\n",
    "        import pandas as pd\n",
    "        from datetime import timedelta\n",
    "        import glob\n",
    "        \n",
    "        if self.cases_file_date is None:\n",
    "            import glob, os\n",
    "\n",
    "            list_of_files = glob.glob(self.datapath+'COVID-19 UoM*.xlsx') \n",
    "            path = max(list_of_files, key=os.path.getctime)\n",
    "            print(\"Using file \"+path)\n",
    "        else:\n",
    "            path = self.datapath+\"COVID-19 UoM \"+self.cases_file_date+\"*.xlsx\"\n",
    "\n",
    "        for file in glob.glob(path):\n",
    "            df = pd.read_excel(file,\n",
    "                       parse_dates=['SPECIMEN_DATE','NOTIFICATION_DATE','NOTIFICATION_RECEIVE_DATE','TRUE_ONSET_DATE'],\n",
    "                       dtype= {'PLACE_OF_ACQUISITION':str})\n",
    "        if len(glob.glob(path))!=1:\n",
    "            print(\"There are %i files with the same date\" %len(glob.glob(path)))\n",
    "        \n",
    "            if len(glob.glob(path)) >1:\n",
    "                print(\"Using an arbritary file\")\n",
    "        df = df.loc[df.STATE==self.state]\n",
    "\n",
    "        #Set imported cases, local cases have 1101 as first 4 digits\n",
    "        df.PLACE_OF_ACQUISITION.fillna('00038888',inplace=True) #Fill blanks with simply unknown\n",
    "\n",
    "        df['date_inferred'] = df.TRUE_ONSET_DATE\n",
    "        df.loc[df.TRUE_ONSET_DATE.isna(),'date_inferred'] = df.loc[df.TRUE_ONSET_DATE.isna()].NOTIFICATION_DATE - timedelta(days=5)\n",
    "        df.loc[df.date_inferred.isna(),'date_inferred'] = df.loc[df.date_inferred.isna()].NOTIFICATION_RECEIVE_DATE - timedelta(days=6)\n",
    "\n",
    "        df['imported'] = df.PLACE_OF_ACQUISITION.apply(lambda x: 1 if x[-4:]=='8888' and x != '00038888' else 0)\n",
    "        df['local'] = 1 - df.imported\n",
    "                \n",
    "        if self.state=='VIC':\n",
    "            #data quality issue\n",
    "            df.loc[df.date_inferred=='2002-07-03','date_inferred'] = pd.to_datetime('2020-07-03')\n",
    "            df.loc[df.date_inferred=='2002-07-17','date_inferred'] = pd.to_datetime('2020-07-17')\n",
    "        df = df.groupby(['date_inferred'])[['imported','local']].sum()\n",
    "        df.reset_index(inplace=True)\n",
    "        df['date'] = df.date_inferred.apply(lambda x: x.dayofyear) -self.start_date.dayofyear\n",
    "        df = df.sort_values(by='date')\n",
    "\n",
    "        self.max_cases = max(500000,10*sum(df.local.values) + sum(df.imported.values))\n",
    "        self.max_backcast_cases = max(100,4*sum(df.local.values) + sum(df.imported.values))\n",
    "        #self.max_cases = max(self.max_cases, 1000)\n",
    "        df = df.set_index('date')\n",
    "        #fill missing dates with 0 up to end_time\n",
    "        df = df.reindex(range(self.end_time), fill_value=0)\n",
    "        self.actual = df.local.to_dict()\n",
    "       \n",
    "        return None\n",
    "\n",
    "    def p_travel(self):\n",
    "        \"\"\"\n",
    "        given a state to go to, what it probability of travel? \n",
    "        \"\"\"\n",
    "        ##Pop from Rob's work\n",
    "        pop = {\n",
    "            'NSW': 5730000,\n",
    "            'VIC': 5191000,\n",
    "            'SA': 1408000,\n",
    "            'WA': 2385000,\n",
    "            'TAS': 240342,\n",
    "            'NT': 154280,\n",
    "            'ACT': 410199,\n",
    "            'QLD': 2560000,\n",
    "        }\n",
    "        T_volume_ij = {\n",
    "            'NSW':{\n",
    "                'ACT':3000,\n",
    "                #'NT':?,\n",
    "                'SA':5300,\n",
    "                'VIC':26700,\n",
    "                'QLD':14000,\n",
    "                'TAS':2500,\n",
    "                'WA':5000,\n",
    "            },\n",
    "            'VIC':{\n",
    "                'ACT':3600,\n",
    "                'NSW':26700,\n",
    "                'SA':12700,\n",
    "                'QLD':11000,\n",
    "                'TAS':5000,\n",
    "                'WA':6000,\n",
    "                #'NT':,\n",
    "            },\n",
    "            'SA':{\n",
    "                'ACT':1200,\n",
    "                'NSW':5300,\n",
    "                'QLD':2500,\n",
    "                #'TAS':,\n",
    "                'VIC':12700,\n",
    "                'WA':2000,\n",
    "            },\n",
    "            \n",
    "        }\n",
    "        #air and car travel from VIC to SA divided by pop of VIC\n",
    "        try:\n",
    "            p = T_volume_ij[\n",
    "                    self.state][self.cross_border_state\n",
    "                    ]/(pop[self.state]+pop[self.cross_border_state])\n",
    "        except KeyError:\n",
    "            print(\"Cross border state not implemented yet\")\n",
    "            raise KeyError\n",
    "        return p\n",
    "    def cross_border_sim(self,parent_key,day:int):\n",
    "        \"\"\"\n",
    "        Simulate a cross border interaction between two states, where \n",
    "        export_state is the state in which a case is coming from.\n",
    "\n",
    "        Need to feed in people, can be blank in attributes\n",
    "\n",
    "        Feed in a time series of cases? Read in the timeseries?\n",
    "        \"\"\"\n",
    "        import pandas as pd\n",
    "        import numpy as np\n",
    "        from math import ceil\n",
    "\n",
    "        from collections import deque\n",
    "        Reff = self.choose_random_item(self.Reff_travel[day])\n",
    "        self.travel_infected_queue = deque()\n",
    "        self.travel_people = {}\n",
    "        #check parent category   \n",
    "        if self.people[parent_key].category=='S':\n",
    "            num_offspring = nbinom.rvs(self.k, 1- self.alpha_s*Reff/(self.alpha_s*Reff + self.k))\n",
    "        elif self.people[parent_key].category=='A':\n",
    "            num_offspring = nbinom.rvs(n=self.k, p = 1- self.alpha_a*Reff/(self.alpha_a*Reff + self.k))\n",
    "        else:\n",
    "            #Is imported\n",
    "            if self.R_I is not None:\n",
    "                #if splitting imported from local, change Reff to R_I \n",
    "                Reff = self.choose_random_item(self.R_I)\n",
    "            if self.people[parent_key].infection_time < self.quarantine_change_date:\n",
    "                #factor of 3 times infectiousness prequarantine changes\n",
    "\n",
    "                num_offspring = nbinom.rvs(n=self.k, p = 1- self.qua_ai*Reff/(self.qua_ai*Reff + self.k))\n",
    "            else:\n",
    "                num_offspring = nbinom.rvs(n=self.k, p = 1- self.alpha_i*Reff/(self.alpha_i*Reff + self.k))\n",
    "        if num_offspring >0:\n",
    "            #import was successful, generate first gen offspring\n",
    "            num_sympcases = self.new_symp_cases(num_offspring)\n",
    "            for new_case in range(num_offspring):\n",
    "                inf_time = next(self.get_inf_time) + self.people[parent_key].infection_time\n",
    "                if inf_time < day +1:\n",
    "                    #record seeded\n",
    "                    if ceil(inf_time) > self.cases.shape[0]:\n",
    "                        #new infection exceeds the simulation time, not recorded\n",
    "                        self.travel_cases_after = self.travel_cases_after + 1\n",
    "                    else:\n",
    "                        self.cross_border_seeds[day-1,self.num_of_sim] += 1\n",
    "                        #successful only if day trip\n",
    "                        detection_rv = 1 #random() zeroed to just see all travel for now\n",
    "                        detect_time = 0 #give 0 by default, fill in if passes\n",
    "                            \n",
    "                        recovery_time = 0 #for now not tracking recoveries\n",
    "                        \n",
    "                        if new_case <= num_sympcases-1: #minus 1 as new_case ranges from 0 to num_offspring-1 \n",
    "                            #first num_sympcases are symnptomatic, rest are asymptomatic\n",
    "                            category = 'S'\n",
    "                            #record all cases the same for now\n",
    "                            self.cross_border_state_cases[max(0,ceil(inf_time)-1),self.num_of_sim] += 1\n",
    "                            \n",
    "                            if detection_rv < self.qs:\n",
    "                                #case detected\n",
    "                                detect_time = inf_time + next(self.get_detect_time)\n",
    "                                if detect_time < self.cases.shape[0]:\n",
    "                                    print(\"placeholder\")\n",
    "                                    #self.observed_cases[max(0,ceil(detect_time)-1),2] += 1\n",
    "\n",
    "                        else:\n",
    "                            category = 'A'\n",
    "                            self.cross_border_state_cases[max(0,ceil(inf_time)-1),self.num_of_sim] +=1\n",
    "                            detect_time = 0\n",
    "                            if detection_rv < self.qa:\n",
    "                                #case detected\n",
    "                                detect_time = inf_time + next(self.get_detect_time)\n",
    "                                if detect_time < self.cases.shape[0]:\n",
    "                                    print(\"placeholder\")\n",
    "                                    #self.observed_cases[max(0,ceil(detect_time)-1),1] += 1\n",
    "\n",
    "                        #add new infected to queue\n",
    "                        self.travel_infected_queue.append(len(self.people))\n",
    "\n",
    "                        #add person to tracked people\n",
    "                        self.travel_people[len(self.people)] = Person(parent_key, inf_time, detect_time,recovery_time, category)\n",
    "\n",
    "\n",
    "\n",
    "                \n",
    "                    \n",
    "        while len(self.travel_infected_queue) >0:\n",
    "            parent_key = self.travel_infected_queue.popleft()\n",
    "            inf_day = ceil(self.travel_people[parent_key].infection_time)\n",
    "            Reff = self.choose_random_item(self.Reff_travel[inf_day])\n",
    "            self.generate_travel_cases(parent_key, Reff)\n",
    "    \n",
    "        return None\n",
    "            \n",
    "\n",
    "    def generate_travel_cases(self,parent_key,Reff):\n",
    "        \"\"\"\n",
    "        Generate and record cases in cross border state \n",
    "        \"\"\"\n",
    "        from math import ceil\n",
    "        #check parent category   \n",
    "        if self.travel_people[parent_key].category=='S':\n",
    "            num_offspring = nbinom.rvs(self.k, 1- self.alpha_s*Reff/(self.alpha_s*Reff + self.k))\n",
    "        elif self.travel_people[parent_key].category=='A':\n",
    "            num_offspring = nbinom.rvs(n=self.k, p = 1- self.alpha_a*Reff/(self.alpha_a*Reff + self.k))\n",
    "        else:\n",
    "            #Is imported\n",
    "            if self.R_I is not None:\n",
    "                #if splitting imported from local, change Reff to R_I \n",
    "                Reff = self.choose_random_item(self.R_I)\n",
    "                num_offspring = nbinom.rvs(n=self.k, p = 1- self.alpha_i*Reff/(self.alpha_i*Reff + self.k))\n",
    "\n",
    "        if num_offspring >0:\n",
    "            num_sympcases = self.new_symp_cases(num_offspring)\n",
    "            for new_case in range(num_offspring):\n",
    "                inf_time = next(self.get_inf_time) + self.travel_people[parent_key].infection_time\n",
    "                if inf_time < self.cases.shape[0]:\n",
    "                    #record case\n",
    "                    self.cross_border_state_cases[max(0,ceil(inf_time)-1),self.num_of_sim] += 1\n",
    "                    detection_rv = 1 #random() zeroed to just see all travel for now\n",
    "                    detect_time = 0 #give 0 by default, fill in if passes\n",
    "                        \n",
    "                    recovery_time = 0 #for now not tracking recoveries\n",
    "                    \n",
    "                    if new_case <= num_sympcases-1: #minus 1 as new_case ranges from 0 to num_offspring-1 \n",
    "                        #first num_sympcases are symnptomatic, rest are asymptomatic\n",
    "                        category = 'S'\n",
    "                        #record all cases the same for now\n",
    "                        self.cross_border_state_cases[max(0,ceil(inf_time)-1),self.num_of_sim] += 1\n",
    "                        \n",
    "                        if detection_rv < self.qs:\n",
    "                            #case detected\n",
    "                            detect_time = inf_time + next(self.get_detect_time)\n",
    "                            if detect_time < self.cases.shape[0]:\n",
    "                                print(\"placeholder\")\n",
    "                                #self.observed_cases[max(0,ceil(detect_time)-1),2] += 1\n",
    "\n",
    "                    else:\n",
    "                        category = 'A'\n",
    "                        self.cross_border_state_cases[max(0,ceil(inf_time)-1),self.num_of_sim] +=1\n",
    "                        detect_time = 0\n",
    "                        if detection_rv < self.qa:\n",
    "                            #case detected\n",
    "                            detect_time = inf_time + next(self.get_detect_time)\n",
    "                            if detect_time < self.cases.shape[0]:\n",
    "                                print(\"placeholder\")\n",
    "                                #self.observed_cases[max(0,ceil(detect_time)-1),1] += 1\n",
    "\n",
    "            \n",
    "                    #add new infected to queue\n",
    "                    self.travel_infected_queue.append(len(self.people))\n",
    "\n",
    "                    #add person to tracked people\n",
    "                    self.travel_people[len(self.people)] = Person(parent_key, inf_time, detect_time,recovery_time, category)\n",
    "                else:\n",
    "                    #new infection exceeds the simulation time, not recorded\n",
    "                    #not added to queue\n",
    "                    self.travel_cases_after = self.travel_cases_after + 1   \n",
    "        return None\n",
    "    \n",
    "    def reset_to_start(self,people):\n",
    "        \"\"\"\n",
    "        Reset forecast object back to initial conditions and reinitialise\n",
    "        \"\"\"\n",
    "        import gc\n",
    "        self.people.clear()\n",
    "        gc.collect()\n",
    "        self.people = people\n",
    "\n",
    "local_detection = {\n",
    "            'NSW':0.8, #0.8 #0.2 #0.556,#0.65,\n",
    "            'QLD':0.9,#0.353,#0.493,#0.74,\n",
    "            'SA':0.7,#0.597,#0.75,\n",
    "            'TAS':0.4,#0.598,#0.48,\n",
    "            'VIC':0.55,#0.558,#0.77,\n",
    "            'WA':0.7,#0.409,#0.509,#0.66,\n",
    "            'ACT':0.95,#0.557,#0.65,\n",
    "            'NT':0.95,#0.555,#0.71\n",
    "        }\n",
    "\n",
    "a_local_detection = {\n",
    "            'NSW':0.05,#0.556,#0.65,\n",
    "            'QLD':0.05,#0.353,#0.493,#0.74,\n",
    "            'SA':0.05,#0.597,#0.75,\n",
    "            'TAS':0.05,#0.598,#0.48,\n",
    "            'VIC':0.05,#0.558,#0.77,\n",
    "            'WA':0.05,#0.409,#0.509,#0.66,\n",
    "            'ACT':0.7,#0.557,#0.65,\n",
    "            'NT':0.7,#0.555,#0.71\n",
    "        }\n",
    "\n",
    "qi_d = {\n",
    "            'NSW':0.95,#0.758,\n",
    "            'QLD':0.95,#0.801,\n",
    "            'SA':0.95,#0.792,\n",
    "            'TAS':0.95,#0.800,\n",
    "            'VIC':0.95,#0.735,\n",
    "            'WA':0.95,#0.792,\n",
    "            'ACT':0.95,#0.771,\n",
    "            'NT':0.95,#0.761\n",
    "    }      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulating state NSW\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from numpy.random import beta, gamma\n",
    "\n",
    "##########\n",
    "#PARAMETERS TO PLAY WITH\n",
    "#########\n",
    "time_end = 30\n",
    "forecast_type = 'R_L0'\n",
    "state = 'NSW'\n",
    "case_file_date = None #'24Jul'\n",
    "#Reff_file_date = '2020-07-20'\n",
    "Reff_file_date = '2020-08-06'\n",
    "#Number of initial symptomatic and asymptomatic cases respectively\n",
    "initial_cases = [10,0]\n",
    "\n",
    "# Laura\n",
    "# sets the seed for only the `action_timeâ€™ for the initial cases, \n",
    "# and so all simulations will start with the same initial cases and the same time to action\n",
    "np.random.seed(1)\n",
    "\n",
    "#############\n",
    "### These parameters do not need to be changed, ask DL\n",
    "XBstate = None\n",
    "start_date = '2020-03-01'\n",
    "test_campaign_date = '2020-06-25'\n",
    "test_campaign_factor = 1.25\n",
    "R_I='R_I'\n",
    "abc =False\n",
    "forecast_date = '2020-03-02'\n",
    "##############################\n",
    "\n",
    "\n",
    "\n",
    "print(\"Simulating state \" +state)\n",
    "\n",
    "\n",
    "##Initialise the number of cases as 1st of March data incidence\n",
    "current = {\n",
    "    'ACT':[0,0,0],\n",
    "    'NSW':[10,0,2], #1\n",
    "    'NT':[0,0,0],\n",
    "    'QLD':[2,0,0],\n",
    "    'SA':[2,0,0],\n",
    "    'TAS':[0,0,0],\n",
    "    'VIC':[2,0,0], #1\n",
    "    'WA':[0,0,0],\n",
    " } \n",
    "current ={state: [0,initial_cases[0],initial_cases[1]]}\n",
    "forecast_dict = {}\n",
    "\n",
    "initial_people = ['I']*current[state][0] + \\\n",
    "        ['A']*current[state][1] + \\\n",
    "        ['S']*current[state][2]\n",
    "people = {}\n",
    "\n",
    "if abc:\n",
    "    qs_prior = beta(2,2,size=10000)\n",
    "    qi_prior = beta(2, 2, size=10000)\n",
    "    qa_prior = beta(2,2, size=10000)\n",
    "    #qi_prior = [qi_d[state]]\n",
    "    #qs_prior = [local_detection[state]]\n",
    "    #qa_prior = [a_local_detection[state]]\n",
    "    gam =0.1 + beta(2,2,size=10000) *0.9 #np.minimum(3,gamma(4,0.25, size=1000))\n",
    "    ps_prior = 0.1+beta(2,2,size=10000)*0.9\n",
    "\n",
    "else:\n",
    "    qi_prior = [qi_d[state]]\n",
    "    qs_prior = [local_detection[state]]\n",
    "    qa_prior = [a_local_detection[state]]\n",
    "    gam =[1/2]\n",
    "    ps_prior = 0.7\n",
    "    ps_prior= [ps_prior]\n",
    "\n",
    "##create dictionary to input intial People\n",
    "# Laura\n",
    "# give action_times to each initial case\n",
    "t_a_shape = 3/2\n",
    "t_a_scale = 2\n",
    "for i,cat in enumerate(initial_people):\n",
    "    people[i] = Person(0,0,0,1,cat, action_time = gamma(t_a_shape,t_a_scale))\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "#create forecast object    \n",
    "if state in ['VIC']:\n",
    "    #XBstate = 'SA'\n",
    "    Model = Forecast(current[state],\n",
    "    state,start_date,people,\n",
    "    alpha_i= 1, k =0.1,gam_list=gam,\n",
    "    qs_list=qs_prior,qi_list=qi_prior,qa_list=qa_prior,\n",
    "    qua_ai=1,qua_qi_factor=1,qua_qs_factor=1,\n",
    "    forecast_R =forecast_type, R_I = R_I,forecast_date=forecast_date,\n",
    "    cross_border_state=XBstate,cases_file_date=case_file_date,\n",
    "    ps_list = ps_prior, test_campaign_date=test_campaign_date, \n",
    "    test_campaign_factor=test_campaign_factor,Reff_file_date=Reff_file_date\n",
    "    )\n",
    "elif state in ['NSW']:\n",
    "    Model = Forecast(current[state],\n",
    "    state,start_date,people,\n",
    "    alpha_i= 1, k =0.1,gam_list=gam,\n",
    "    qs_list=qs_prior,qi_list=qi_prior,qa_list=qa_prior,\n",
    "    qua_ai=1,qua_qi_factor=1,qua_qs_factor=1,\n",
    "    forecast_R =forecast_type, R_I = R_I,forecast_date=forecast_date,\n",
    "    cross_border_state=None,cases_file_date=case_file_date,\n",
    "    ps_list = ps_prior,Reff_file_date=Reff_file_date\n",
    "    )\n",
    "elif state in ['ACT','NT','SA','WA','QLD']:\n",
    "    Model = Forecast(current[state],\n",
    "    state,start_date,people,\n",
    "    alpha_i= 0.1, k =0.1,gam_list=gam,\n",
    "    qs_list=qs_prior,qi_list=qi_prior,qa_list=qa_prior,\n",
    "    qua_ai=1,qua_qi_factor=1,qua_qs_factor=1,\n",
    "    forecast_R =forecast_type, R_I = R_I,forecast_date=forecast_date,\n",
    "    cross_border_state=None,cases_file_date=case_file_date,\n",
    "    ps_list = ps_prior,Reff_file_date=Reff_file_date\n",
    "    )\n",
    "else:\n",
    "    Model = Forecast(current[state],state,\n",
    "    start_date,people,\n",
    "    alpha_i= 0.5, k =0.1,gam_list=gam,\n",
    "    qs_list=qs_prior,qi_list=qi_prior,qa_list=qa_prior,\n",
    "    qua_ai=1,qua_qi_factor=1,qua_qs_factor=1, \n",
    "    forecast_R = forecast_type , R_I = R_I,forecast_date=forecast_date,\n",
    "    cases_file_date=case_file_date,\n",
    "    ps_list = ps_prior,Reff_file_date=Reff_file_date\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using file /Users/dennisliu/Documents/GitHub/covid19-forecasting-aus/model/contact_tracing/../../data/COVID-19 UoM 19Oct2020 1515.xlsx\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Set up some required attributes for simulation\n",
    "Model.end_time = time_end\n",
    "Model.cross_border_seeds = np.zeros(shape=(time_end,1000),dtype=int)\n",
    "Model.cross_border_state_cases = np.zeros_like(Model.cross_border_seeds)\n",
    "\n",
    "Model.num_bad_sims = 0\n",
    "Model.num_too_many = 0\n",
    "        \n",
    "#Read in files\n",
    "Model.read_in_Reff()\n",
    "Model.read_in_cases()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean is 1.28\n",
      "90 percent interval is 1.11 and 1.56\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "factor = 0.6\n",
    "ax.hist(factor*Model.Reff[0])\n",
    "print(\"Mean is %.2f\" % np.mean(factor*Model.Reff[0]))\n",
    "print(\"90 percent interval is %.2f and %.2f\" % tuple(np.quantile(factor*Model.Reff[0], (0.05,0.95)) ))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0., 17., 18.],\n",
       "        [ 0.,  3.,  2.],\n",
       "        [ 0.,  4.,  4.],\n",
       "        [ 0.,  0.,  5.],\n",
       "        [ 0.,  1.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  3.],\n",
       "        [ 0.,  4.,  4.],\n",
       "        [ 0.,  7., 10.],\n",
       "        [ 0.,  8., 11.],\n",
       "        [ 0.,  8., 20.],\n",
       "        [ 0.,  6., 21.],\n",
       "        [ 0.,  5., 12.],\n",
       "        [ 0.,  7., 12.],\n",
       "        [ 0.,  5.,  8.],\n",
       "        [ 0.,  5., 10.],\n",
       "        [ 0.,  5., 18.],\n",
       "        [ 0.,  8., 13.],\n",
       "        [ 0.,  8., 12.],\n",
       "        [ 0.,  3., 17.],\n",
       "        [ 0.,  7.,  9.],\n",
       "        [ 0.,  6., 20.],\n",
       "        [ 0., 11., 13.],\n",
       "        [ 0.,  5., 13.],\n",
       "        [ 0.,  2., 13.],\n",
       "        [ 0.,  6., 10.],\n",
       "        [ 0.,  3.,  7.],\n",
       "        [ 0.,  1., 10.],\n",
       "        [ 0.,  2.,  0.],\n",
       "        [ 0.,  2.,  5.]]),\n",
       " array([[ 0., 10.,  3.],\n",
       "        [ 0.,  0.,  2.],\n",
       "        [ 0.,  1., 10.],\n",
       "        [ 0.,  0.,  2.],\n",
       "        [ 0.,  0.,  3.],\n",
       "        [ 0.,  0.,  2.],\n",
       "        [ 0.,  0.,  1.],\n",
       "        [ 0.,  0.,  2.],\n",
       "        [ 0.,  0.,  2.],\n",
       "        [ 0.,  0.,  4.],\n",
       "        [ 0.,  0.,  8.],\n",
       "        [ 0.,  0., 10.],\n",
       "        [ 0.,  0., 13.],\n",
       "        [ 0.,  1., 14.],\n",
       "        [ 0.,  0., 13.],\n",
       "        [ 0.,  0.,  7.],\n",
       "        [ 0.,  0.,  8.],\n",
       "        [ 0.,  1.,  8.],\n",
       "        [ 0.,  0., 15.],\n",
       "        [ 0.,  0., 11.],\n",
       "        [ 0.,  0.,  9.],\n",
       "        [ 0.,  0., 11.],\n",
       "        [ 0.,  0., 11.],\n",
       "        [ 0.,  0., 12.],\n",
       "        [ 0.,  1.,  7.],\n",
       "        [ 0.,  0.,  9.],\n",
       "        [ 0.,  0., 17.],\n",
       "        [ 0.,  0.,  9.],\n",
       "        [ 0.,  0.,  9.],\n",
       "        [ 0.,  0.,  6.]]),\n",
       " {'qs': 0.8,\n",
       "  'metric': 47977.0,\n",
       "  'qa': 0.05,\n",
       "  'qi': 0.95,\n",
       "  'alpha_a': 0.5882352941176471,\n",
       "  'alpha_s': 1.1764705882352942,\n",
       "  'ps': 0.7,\n",
       "  'bad_sim': False,\n",
       "  'Model_people': 449,\n",
       "  'cases_after': 7,\n",
       "  'travel_seeds': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  'travel_induced_casesNone': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  'num_of_sim': 1})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#simulate takes arguments days, sim number, and seed\n",
    "## It will return:\n",
    "## cases: a n_days by 3 array where each column represents \n",
    "##         Imported, Asymptomatic and Symptomatic cases, in that order.\n",
    "##        Cases are indexed in time by rows by their date of infection.\n",
    "## observed_cases: a n_days by 3 array, same as cases, but only observed cases, \n",
    "##        and are indexed in time by their date of symptom onset.\n",
    "\n",
    "N=1\n",
    "p_c=1.0\n",
    "DAYS = 2\n",
    "Model.simulate(time_end,1,N)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sim number 0 \n",
      "Timeline of Cases:\n",
      " [[ 0. 13. 12.]\n",
      " [ 0.  1.  5.]\n",
      " [ 0.  0.  2.]\n",
      " [ 0.  1.  4.]\n",
      " [ 0.  1.  7.]\n",
      " [ 0.  2.  1.]\n",
      " [ 0.  4.  8.]\n",
      " [ 0.  1. 10.]\n",
      " [ 0.  6. 11.]\n",
      " [ 0.  7. 18.]\n",
      " [ 0.  3. 23.]\n",
      " [ 0. 10. 20.]\n",
      " [ 0. 15. 23.]\n",
      " [ 0. 18. 23.]\n",
      " [ 0. 17. 34.]\n",
      " [ 0. 21. 33.]\n",
      " [ 0. 15. 19.]\n",
      " [ 0. 19. 35.]\n",
      " [ 0.  9. 25.]\n",
      " [ 0. 12. 41.]\n",
      " [ 0. 26. 51.]\n",
      " [ 0. 27. 80.]\n",
      " [ 0. 30. 72.]\n",
      " [ 0. 38. 81.]\n",
      " [ 0. 25. 58.]\n",
      " [ 0. 19. 46.]\n",
      " [ 0. 25. 52.]\n",
      " [ 0. 28. 42.]\n",
      " [ 0. 14. 36.]\n",
      " [ 0. 11. 36.]]\n",
      "Length of People (CasesTotal): 1535 \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-577e7cae0f52>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mpc_100_day_N3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mN\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mcases_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobserved_cases_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimulate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime_end\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m#v = list(x)[2]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-d6fe9ff17c34>\u001b[0m in \u001b[0;36msimulate\u001b[0;34m(self, end_time, sim, seed)\u001b[0m\n\u001b[1;32m    939\u001b[0m         \u001b[0;31m#LB needs people recorded, do not clear this attribute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    940\u001b[0m         \u001b[0;31m#self.people.clear()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 941\u001b[0;31m         \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    942\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbad_sim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    943\u001b[0m             \u001b[0;31m#return NaN arrays for all bad_sims\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Simulation study for delay time\n",
    "\n",
    "t_a_shape = 3/2\n",
    "t_a_scale = 2\n",
    "\n",
    "n=1000\n",
    "\n",
    "DAYS = 3\n",
    "p_c = 1\n",
    "pc_100_day_N3 = []\n",
    "for N in range(0, n):\n",
    "    cases_array, observed_cases_array, params = Model.simulate(time_end,1,N)\n",
    "    \n",
    "    #v = list(x)[2]\n",
    "    #v2 = v.values()\n",
    "    Cases = params['Model_people']\n",
    "    CasesAfter = params['cases_after']\n",
    "    CasesTotal = Cases + CasesAfter\n",
    "\n",
    "    pc_100_day_N3.append((CasesTotal))\n",
    "    \n",
    "    if N%100==0:\n",
    "        print(\"sim number %i \" % N)\n",
    "        print(\"Timeline of Cases:\\n\", cases_array)\n",
    "        print(\"Length of People (CasesTotal): %i \" % CasesTotal)\n",
    "\n",
    "print('Completed Days = -3 , p = 1.0')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trace back branches\n",
    "\n",
    "#Look at the last person \n",
    "#Model.people[len(Model.people)-1].__dict__\n",
    "\n",
    "#Model.people[4].__dict__\n",
    "\n",
    "\n",
    "\n",
    "Model.people[29].__dict__\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at a person in the people dictionary\n",
    "Model.people[7].__dict__\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at the last person \n",
    "Model.people[len(Model.people)-1].__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laura\n",
    "# Look at people in order\n",
    "Model.people[2].__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laura\n",
    "# Total number of people infected\n",
    "len(Model.people)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#how many offspring are in the next generation after simulation end_date\n",
    "Model.cases_after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Delay distribution\n",
    "fig,ax = plt.subplots(figsize=(12,9))\n",
    "#x = np.random.gamma(5/2, 2, size = 10000)\n",
    "x = np.random.gamma(3/2, 2, size = 10000)\n",
    "print(\"Mean: %f.2\" %np.mean(x))\n",
    "print(\"Variance: %f.2\" %np.var(x))\n",
    "ax.hist(x,bins=40)\n",
    "ax.set_title(\"Time to action distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reproduction number for day n\n",
    "#if forecast_type is R_L0, then every day has the same distribution for Reff\n",
    "# which is baseline for 1st March with no social distancing in Aus.\n",
    "n = 30\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.hist(Model.Reff[n],bins=30)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Infection time distribution\n",
    "fig,ax = plt.subplots(figsize=(12,9))\n",
    "x = 1+np.random.gamma(3.5/0.5, 0.5, size = 10000)\n",
    "print(\"Mean: %f.2\" %np.mean(x))\n",
    "print(\"Variance: %f.2\" %np.var(x))\n",
    "ax.hist(x,bins=40)\n",
    "ax.set_title(\"Generation time distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.quantile(x,0.4)) #infection time\n",
    "y = 1+np.random.gamma(3/1, 1, size = 10000) #symptom time\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(y, bins=40)\n",
    "#ax.hist(y-x,bins =40)\n",
    "\n",
    "print(np.percentile(y-x, 40))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Observation time distribution\n",
    "fig,ax = plt.subplots(figsize=(12,9))\n",
    "y = np.random.gamma(5*5/1, 1/5, size = 10000)\n",
    "y = [yi for yi in y if yi >2]\n",
    "print(\"Mean: %f.2\" %np.mean(y))\n",
    "print(\"Variance: %f.2\" %np.var(y))\n",
    "ax.hist(y,bins=40)\n",
    "ax.set_title(\"Observation time distribution\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Symptom onset time distribution\n",
    "fig,ax = plt.subplots(figsize=(12,9))\n",
    "y = np.random.gamma(5.807/0.948, 0.948, size = 10000)\n",
    "\n",
    "print(\"Mean: %f.2\" %np.mean(y))\n",
    "print(\"Variance: %f.2\" %np.var(y))\n",
    "print(\"95 percent interval is %.2f to %.2f\" % (np.quantile(y,0.025), np.quantile(y,0.975)) )\n",
    "ax.hist(y,bins=40)\n",
    "ax.set_title(\"Symptom time distribution\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Symptom onset time distribution\n",
    "fig,ax = plt.subplots(figsize=(12,9))\n",
    "y = np.random.gamma(5.807/0.948, 0.948, size = 10000)\n",
    "\n",
    "print(\"Mean: %f.2\" %np.mean(y))\n",
    "print(\"Variance: %f.2\" %np.var(y))\n",
    "print(\"95 percent interval is %.2f to %.2f\" % (np.quantile(y,0.025), np.quantile(y,0.975)) )\n",
    "ax.hist(y,bins=40)\n",
    "ax.set_title(\"Symptom time distribution\")\n",
    "#Symptom onset time distribution\n",
    "fig,ax = plt.subplots(figsize=(12,9))\n",
    "y = 2+np.random.gamma(3/1, 1, size = 10000)\n",
    "\n",
    "print(\"Mean: %f.2\" %np.mean(y))\n",
    "print(\"Variance: %f.2\" %np.var(y))\n",
    "print(\"95 percent interval is %.2f to %.2f\" % (np.quantile(y,0.025), np.quantile(y,0.975)) )\n",
    "ax.hist(y,bins=40)\n",
    "ax.set_title(\"Symptom time distribution\")\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Neg Binomial offspring distribution\n",
    "Reff=1.4\n",
    "n = 3\n",
    "p = 1- Reff/(Reff+k)\n",
    "fig,ax = plt.subplots(figsize=(12,9))\n",
    "rv = nbinom(n, p)\n",
    "x = np.arange(nbinom.ppf(0.01, n, p),\n",
    "          nbinom.ppf(0.99, n, p))\n",
    "ax.vlines(x, 0, rv.pmf(x), colors='k', linestyles='-', lw=1,\n",
    "     label='frozen pmf')\n",
    "\n",
    "print(\"Mean: %f.2\" % nbinom.stats(n,p)[0])\n",
    "print(\"Variance: %f.2\" %nbinom.stats(n,p)[1])\n",
    "\n",
    "ax.set_title(\"Offspring distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check Neg Binom distribution \n",
    "k=0.1\n",
    "\n",
    "Reff = pd.read_hdf('../data/soc_mob_R2020-06-22.h5',\n",
    "            key='Reff')\n",
    "\n",
    "R = Reff.loc[(Reff.type=='R_L')&(Reff.state=='VIC'),['date']+list(range(99))]\n",
    "R = R.loc[R.date>='2020-06-15']\n",
    "fig,ax = plt.subplots(figsize=(12,9))\n",
    "ax.plot(R.date, 0.89*R[range(99)].median(axis=1))\n",
    "num_offspring = nbinom.rvs(k, 1- 0.89*R[range(99)]/(0.89*R[range(99)] + k))\n",
    "\n",
    "bins = np.bincount(num_offspring)\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(12,9))\n",
    "ax.vlines(range(len(bins)),0, bins)\n",
    "\n",
    "print(\"Mean is %.2f\" %np.mean(num_offspring))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 0.1\n",
    "alpha_s = 0\n",
    "R_L = 0.3\n",
    "p = 1 - alpha_s* R_L/ (alpha_s*R_L + k)\n",
    "x = nbinom.rvs(k ,p,size=100000)\n",
    "\n",
    "#plotting\n",
    "print(\"mean should be %.4f \" % (alpha_s*R_L))\n",
    "print(\"Mean is %.4f\" % np.mean(x))\n",
    "print(\"Variance is %.2f \" %np.var(x))\n",
    "fig,ax = plt.subplots()\n",
    "ax.vlines(range(len(np.bincount(x))),0,np.bincount(x))\n",
    "ax.set_xlim((0,15))\n",
    "plt.locator_params(axis='x', nbins=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## imports NT\n",
    "alpha = 15\n",
    "b = 22.2\n",
    "\n",
    "p = 1 - 1/ (1 + b)\n",
    "x = nbinom.rvs(alpha ,p,size=10000)\n",
    "\n",
    "#plotting\n",
    "print(\"Mean is %.4f\" % np.mean(x))\n",
    "print(\"Variance is %.2f \" %np.var(x))\n",
    "fig,ax = plt.subplots()\n",
    "ax.vlines(range(len(np.bincount(x))),0,np.bincount(x))\n",
    "#ax.set_xlim((0,15))\n",
    "plt.locator_params(axis='x', nbins=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Posterior predictive distribution of imports\n",
    "a_dict = {\n",
    "            'ACT': {\n",
    "                1:10,\n",
    "                2:21,\n",
    "                3:22,\n",
    "                4:2\n",
    "            },\n",
    "            'NSW': {\n",
    "                1: 315,\n",
    "                2: 620,\n",
    "                3: 799,\n",
    "                4: 19,\n",
    "            },\n",
    "            'NT': {\n",
    "                1: 4,\n",
    "                2: 6,\n",
    "                3: 17,\n",
    "                4: 3,\n",
    "            },\n",
    "            'QLD': {\n",
    "                1:170,\n",
    "                2:268,\n",
    "                3:351,\n",
    "                4:14,\n",
    "            },\n",
    "            'SA': {\n",
    "                1:44,\n",
    "                2:124,\n",
    "                3:125,\n",
    "                4:5,\n",
    "            },\n",
    "            'TAS':{\n",
    "                1:10,\n",
    "                2:31,\n",
    "                3:39,\n",
    "                4:2,\n",
    "\n",
    "            },\n",
    "            'VIC': {\n",
    "                1:150,\n",
    "                2:158,\n",
    "                3:223,\n",
    "                4:22,\n",
    "            },\n",
    "            'WA': {\n",
    "                1:78,\n",
    "                2:114,\n",
    "                3:255,\n",
    "                4:3,\n",
    "            },\n",
    "        }\n",
    "\n",
    "b_dict = {\n",
    "            1: 14.2,\n",
    "            2: 5.2,\n",
    "            3: 26.2,\n",
    "            4: 23.2\n",
    "        }\n",
    "        \n",
    "\n",
    "## Check Neg Binom distribution \n",
    "a = a_dict['NSW'][2]\n",
    "b = b_dict[2]\n",
    "num_offspring = nbinom.rvs(a, 1- 1/(b + 1),size=1000)\n",
    "\n",
    "bins = np.bincount(num_offspring)\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(12,9))\n",
    "ax.vlines(range(len(bins)),0, bins)\n",
    "\n",
    "print(\"Mean is %.2f\" %np.mean(num_offspring))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From numpy (but not scipy), the probability density for the negative binomial distribution is\n",
    "\n",
    "\\begin{equation}\n",
    "P(N ; n, p)={N+n-1 \\choose n-1} p^{n}(1-p)^{N} \\\\\n",
    "\\end{equation}\n",
    "where $n-1$ is the number of successes, $p$ is the probability of success, and $N+n-1$ is the number of trials. The negative binomial distribution gives the probability of $n-1$ successes and $N$ failures in $N+n-1$ trials, and success on the (N+n)th trial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_i = 0.1\n",
    "Reff=2.2\n",
    "k = 3\n",
    "p = alpha_i*Reff/(alpha_i*Reff + k)\n",
    "print(\"Probability of a success is: %.3f\" % p)\n",
    "nbinomI = nbinom(k,1-p)\n",
    "samples = nbinomI.rvs(size=1000)\n",
    "print(\"mean is: %.2f\" % np.mean(samples))\n",
    "ax = plt.hist(samples)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_nbinom(s, k, p):\n",
    "    \"\"\"\n",
    "    my own nbinom, s= failures, k = successes, p = probability of success\n",
    "    \"\"\"\n",
    "    \n",
    "    from scipy.special import comb\n",
    "    \n",
    "    return comb(k+s-1,s)* p**k*(1-p)**s\n",
    "\n",
    "pdf = []\n",
    "for s in np.arange(0,10):\n",
    "    pdf.append(my_nbinom(s,3 ,1-p))\n",
    "    \n",
    "plt.bar(np.arange(0,10),pdf)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Reff=2.2\n",
    "k = 3\n",
    "p =1- Reff/(Reff + k)\n",
    "print(\"Probability of a success is: %.3f\" % p)\n",
    "nbinomI = nbinom(n=k, p = p )\n",
    "samples = nbinomI.rvs(size=100)\n",
    "print(\"Mean is %.2f\" %np.mean(samples))\n",
    "print(\"Variance is %.2f\" %np.var(samples))\n",
    "ax = plt.hist(samples, bins=20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
